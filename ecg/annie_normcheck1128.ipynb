{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용 전: [-0.6109866 -0.6109866 -0.6109866 ...  1.1395246  1.1395246  1.1395246]\n",
      "------------------------------\n",
      "ReLU 적용 후: tensor([0.0000, 0.0000, 0.0000,  ..., 1.1395, 1.1395, 1.1395])\n",
      "------------------------------\n",
      "LeakyReLU 적용 후: tensor([-0.0061, -0.0061, -0.0061,  ...,  1.1395,  1.1395,  1.1395])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 심전도 데이터 로드\n",
    "lead1_signals = np.load('./custom_file/annie_ptb_xl_lead1.npy')\n",
    "\n",
    "lead1_signals_normalized = (lead1_signals - lead1_signals.mean()) / (lead1_signals.std()+1e-7)\n",
    "\n",
    "# 텐서로 변환\n",
    "lead1_tensor = torch.Tensor(lead1_signals_normalized)\n",
    "\n",
    "# ReLU 적용\n",
    "relu = nn.ReLU()\n",
    "lead1_tensor_relu = relu(lead1_tensor)\n",
    "\n",
    "# ReLU 적용\n",
    "relu = nn.LeakyReLU()\n",
    "lead1_tensor_relu1 = relu(lead1_tensor)\n",
    "\n",
    "# 데이터 출력\n",
    "print(\"적용 전:\", lead1_signals_normalized[0][:-10])\n",
    "print(\"---\"*10)\n",
    "print(\"ReLU 적용 후:\", lead1_tensor_relu[0][:-10])\n",
    "print(\"---\"*10)\n",
    "print(\"LeakyReLU 적용 후:\", lead1_tensor_relu1[0][:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용 전: [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      "------------------------------\n",
      "ReLU 적용 후: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., -0.])\n",
      "------------------------------\n",
      "LeakyReLU 적용 후: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., -0.])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SPH 데이터 로드 및 전처리\n",
    "df_sph = pd.read_csv(\"./sph_data/metadata.csv\", index_col='ECG_ID')\n",
    "# 'AHA_Code' 컬럼의 각 값에 대해 '50'이 포함되어 있는지 확인하고, 'label' 컬럼 생성\n",
    "def check_contains_50(code):\n",
    "    numbers = code.replace(' ', '').replace('+', ';').split(';')\n",
    "    return '50' in numbers\n",
    "\n",
    "df_sph['label'] = df_sph['AHA_Code'].apply(check_contains_50).astype(int)\n",
    "    \n",
    "sph_labels = df_sph['label'].values\n",
    "\n",
    "sph_signals = np.load('./custom_file/annie_sph_lead1.npy')\n",
    "sph_signals_normalized = (sph_signals - sph_signals.mean()) / (sph_signals.std() + 1e-8)\n",
    "\n",
    "X_sph = torch.Tensor(sph_signals_normalized)\n",
    "\n",
    "# ReLU 적용\n",
    "relu = nn.ReLU()\n",
    "lead1_tensor_relu = relu(X_sph)\n",
    "\n",
    "# ReLU 적용\n",
    "relu = nn.LeakyReLU()\n",
    "lead1_tensor_relu1 = relu(X_sph)\n",
    "\n",
    "# 데이터 출력\n",
    "print(\"적용 전:\", sph_signals_normalized[0][:10])\n",
    "print(\"---\"*10)\n",
    "print(\"ReLU 적용 후:\", lead1_tensor_relu[0][:10])\n",
    "print(\"---\"*10)\n",
    "print(\"LeakyReLU 적용 후:\", lead1_tensor_relu1[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용 전: [ 5.0345249e-02  5.0345249e-02  4.8463851e-02  4.2890653e-02\n",
      "  3.7317455e-02  3.1726506e-02  2.4271907e-02  1.3107759e-02\n",
      "  7.9961304e-05 -9.2294114e-03]\n",
      "------------------------------\n",
      "ReLU 적용 후: tensor([5.0345e-02, 5.0345e-02, 4.8464e-02, 4.2891e-02, 3.7317e-02, 3.1727e-02,\n",
      "        2.4272e-02, 1.3108e-02, 7.9961e-05, 0.0000e+00])\n",
      "------------------------------\n",
      "LeakyReLU 적용 후: tensor([ 5.0345e-02,  5.0345e-02,  4.8464e-02,  4.2891e-02,  3.7317e-02,\n",
      "         3.1727e-02,  2.4272e-02,  1.3108e-02,  7.9961e-05, -9.2294e-05])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SPH 데이터 로드 및 전처리\n",
    "df_sph = pd.read_csv(\"./sph_data/metadata.csv\", index_col='ECG_ID')\n",
    "# 'AHA_Code' 컬럼의 각 값에 대해 '50'이 포함되어 있는지 확인하고, 'label' 컬럼 생성\n",
    "def check_contains_50(code):\n",
    "    numbers = code.replace(' ', '').replace('+', ';').split(';')\n",
    "    return '50' in numbers\n",
    "\n",
    "df_sph['label'] = df_sph['AHA_Code'].apply(check_contains_50).astype(int)\n",
    "    \n",
    "sph_labels = df_sph['label'].values\n",
    "\n",
    "sph_signals = np.load('./custom_file/annie_sph_lead1.npy')\n",
    "\n",
    "sph_signals_float = sph_signals.astype(np.float32)\n",
    "mean = np.mean(sph_signals_float)\n",
    "std = np.std(sph_signals_float)\n",
    "sph_signals_normalized = (sph_signals_float - mean) / (std + 1e-7)\n",
    "\n",
    "\n",
    "X_sph = torch.Tensor(sph_signals_normalized)\n",
    "\n",
    "# ReLU 적용\n",
    "relu = nn.ReLU()\n",
    "lead1_tensor_relu = relu(X_sph)\n",
    "\n",
    "# ReLU 적용\n",
    "relu = nn.LeakyReLU()\n",
    "lead1_tensor_relu1 = relu(X_sph)\n",
    "\n",
    "# 데이터 출력\n",
    "print(\"적용 전:\", sph_signals_normalized[0][:10])\n",
    "print(\"---\"*10)\n",
    "print(\"ReLU 적용 후:\", lead1_tensor_relu[0][:10])\n",
    "print(\"---\"*10)\n",
    "print(\"LeakyReLU 적용 후:\", lead1_tensor_relu1[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(sph_signals.dtype)\n",
    "print(lead1_signals.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sph_signals 최소값: -397.0\n",
      "sph_signals 최대값: 573.0\n"
     ]
    }
   ],
   "source": [
    "print(\"sph_signals 최소값:\", np.min(sph_signals))\n",
    "print(\"sph_signals 최대값:\", np.max(sph_signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead1_signals 최소값: -32.692\n",
      "lead1_signals 최대값: 32.716\n"
     ]
    }
   ],
   "source": [
    "print(\"lead1_signals 최소값:\", np.min(lead1_signals))\n",
    "print(\"lead1_signals 최대값:\", np.max(lead1_signals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
